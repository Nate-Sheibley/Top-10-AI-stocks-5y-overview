{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and setup\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# csv paths\n",
    "kaggle_path = \"Resources/kaggle_clean.csv\"\n",
    "dow_path = \"Resources/dow_clean.csv\"\n",
    "indu_path = \"Resources/indu_clean.csv\"\n",
    "spy_path = \"Resources/spy_clean.csv\"\n",
    "\n",
    "# Read the csv files into dataframes - NEW update to to avoid overwriting the file path variables\n",
    "kaggle_df = pd.read_csv(kaggle_path)\n",
    "dow_df = pd.read_csv(dow_path)\n",
    "indu_df = pd.read_csv(indu_path)\n",
    "spy_df = pd.read_csv(spy_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      symbol        date   open   high    low  close    volume\n",
      "0       NVDA  2014-06-02   4.76   4.80   4.70   4.74  18150000\n",
      "10056   PANW  2014-06-02  25.04  25.06  24.00  24.56   6110100\n",
      "12571    NOW  2014-06-02  52.33  52.34  49.46  50.26   3069100\n",
      "2515    META  2014-06-02  63.23  63.59  62.05  63.08  35996000\n",
      "15086    AMD  2014-06-02   4.03   4.03   3.94   3.97  10859500\n",
      "     symbol        date   open   high    low  close   volume\n",
      "1309    DOW  2019-03-20  52.75  53.50  49.50  49.80  2350838\n",
      "1308    DOW  2019-03-21  49.99  50.00  48.20  48.98  1764671\n",
      "1307    DOW  2019-03-22  48.80  49.95  48.16  48.60   844690\n",
      "1306    DOW  2019-03-25  48.60  49.40  48.00  49.15   440892\n",
      "1305    DOW  2019-03-26  49.00  49.75  48.18  48.85   504734\n",
      "     symbol        date  open  high  low  close  volume\n",
      "1704   INDU  2017-08-21  9.81  9.81  9.7   9.70   52682\n",
      "1703   INDU  2017-08-22  9.70  9.70  9.7   9.70   27295\n",
      "1702   INDU  2017-08-23  9.70  9.70  9.7   9.70       5\n",
      "1701   INDU  2017-08-24  9.70  9.70  9.7   9.70   10025\n",
      "1700   INDU  2017-08-25  9.70  9.71  9.7   9.71   29800\n",
      "     symbol        date    open    high     low   close    volume\n",
      "1704    SPY  2017-08-22  243.57  245.62  243.55  245.44  63140101\n",
      "1703    SPY  2017-08-23  244.33  245.05  244.16  244.56  50203837\n",
      "1702    SPY  2017-08-24  245.00  245.18  243.75  243.99  50741671\n",
      "1701    SPY  2017-08-25  244.90  245.61  244.39  244.56  64445912\n",
      "1700    SPY  2017-08-28  245.17  245.20  244.09  244.57  40565606\n"
     ]
    }
   ],
   "source": [
    "# Create list of DataFrames\n",
    "all_csvs = [kaggle_df, dow_df, indu_df, spy_df]\n",
    "\n",
    "# Process each DataFrame\n",
    "for df in all_csvs:   \n",
    "    columns = df.columns.tolist()\n",
    "    columns = ['symbol'] + [col for col in columns if col != 'symbol']\n",
    "    df = df.sort_values(by=\"date\", ascending=True)\n",
    "    df = df[columns]\n",
    "    df = df.round(2)\n",
    "    print(f\"{df.head()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>2014-06-02</td>\n",
       "      <td>4.7650</td>\n",
       "      <td>4.795</td>\n",
       "      <td>4.6950</td>\n",
       "      <td>4.7350</td>\n",
       "      <td>18150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>2014-06-03</td>\n",
       "      <td>4.7450</td>\n",
       "      <td>4.750</td>\n",
       "      <td>4.6525</td>\n",
       "      <td>4.7150</td>\n",
       "      <td>24321200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>2014-06-04</td>\n",
       "      <td>4.7025</td>\n",
       "      <td>4.755</td>\n",
       "      <td>4.7000</td>\n",
       "      <td>4.7200</td>\n",
       "      <td>16123600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>2014-06-05</td>\n",
       "      <td>4.7275</td>\n",
       "      <td>4.755</td>\n",
       "      <td>4.7000</td>\n",
       "      <td>4.7400</td>\n",
       "      <td>18869600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>2014-06-06</td>\n",
       "      <td>4.7625</td>\n",
       "      <td>4.800</td>\n",
       "      <td>4.7450</td>\n",
       "      <td>4.7575</td>\n",
       "      <td>16105200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26483</th>\n",
       "      <td>SPY</td>\n",
       "      <td>2017-08-28</td>\n",
       "      <td>245.1700</td>\n",
       "      <td>245.200</td>\n",
       "      <td>244.0900</td>\n",
       "      <td>244.5700</td>\n",
       "      <td>40565606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26484</th>\n",
       "      <td>SPY</td>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>244.9000</td>\n",
       "      <td>245.610</td>\n",
       "      <td>244.3900</td>\n",
       "      <td>244.5600</td>\n",
       "      <td>64445912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26485</th>\n",
       "      <td>SPY</td>\n",
       "      <td>2017-08-24</td>\n",
       "      <td>245.0000</td>\n",
       "      <td>245.180</td>\n",
       "      <td>243.7500</td>\n",
       "      <td>243.9900</td>\n",
       "      <td>50741671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26486</th>\n",
       "      <td>SPY</td>\n",
       "      <td>2017-08-23</td>\n",
       "      <td>244.3300</td>\n",
       "      <td>245.050</td>\n",
       "      <td>244.1600</td>\n",
       "      <td>244.5600</td>\n",
       "      <td>50203837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26487</th>\n",
       "      <td>SPY</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>243.5700</td>\n",
       "      <td>245.620</td>\n",
       "      <td>243.5500</td>\n",
       "      <td>245.4400</td>\n",
       "      <td>63140101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26488 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      symbol        date      open     high       low     close    volume\n",
       "0       NVDA  2014-06-02    4.7650    4.795    4.6950    4.7350  18150000\n",
       "1       NVDA  2014-06-03    4.7450    4.750    4.6525    4.7150  24321200\n",
       "2       NVDA  2014-06-04    4.7025    4.755    4.7000    4.7200  16123600\n",
       "3       NVDA  2014-06-05    4.7275    4.755    4.7000    4.7400  18869600\n",
       "4       NVDA  2014-06-06    4.7625    4.800    4.7450    4.7575  16105200\n",
       "...      ...         ...       ...      ...       ...       ...       ...\n",
       "26483    SPY  2017-08-28  245.1700  245.200  244.0900  244.5700  40565606\n",
       "26484    SPY  2017-08-25  244.9000  245.610  244.3900  244.5600  64445912\n",
       "26485    SPY  2017-08-24  245.0000  245.180  243.7500  243.9900  50741671\n",
       "26486    SPY  2017-08-23  244.3300  245.050  244.1600  244.5600  50203837\n",
       "26487    SPY  2017-08-22  243.5700  245.620  243.5500  245.4400  63140101\n",
       "\n",
       "[26488 rows x 7 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine kaggle data and index csvs into one csv\n",
    "master_df = pd.concat(all_csvs, ignore_index=True)\n",
    "master_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define path to Resources folder\n",
    "resources_path = \"Resources\"\n",
    "\n",
    "file_path = os.path.join(resources_path, \"master.csv\")\n",
    "master_df.to_csv(file_path, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading df svc file\n",
    "master_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           symbol       open       high        low      close    volume\n",
      "date                                                                   \n",
      "2019-03-20   NVDA  44.220001  44.757500  43.250000  43.599998  71914800\n",
      "2019-03-21   NVDA  43.832500  46.250000  43.782501  45.985001  82431200\n",
      "2019-03-22   NVDA  45.709999  46.200001  44.235001  44.375000  74764400\n",
      "2019-03-25   NVDA  43.965000  44.612499  42.777500  43.445000  52521200\n",
      "2019-03-26   NVDA  44.872501  45.437500  43.650002  44.217499  70350800\n"
     ]
    }
   ],
   "source": [
    "# FILTER DATA to ensure that we compare the stok for the same period, we set up data frame based on data periods avaiailble for free actross all stocks\n",
    "# Convert 'date' column to datetime type to ensure correct filtering\n",
    "master_df['date'] = pd.to_datetime(master_df['date'])\n",
    "\n",
    "# Define the date range\n",
    "start_date = '2019-03-20'\n",
    "end_date = '2024-05-28'\n",
    "\n",
    "# Filter the DataFrame based on the date range\n",
    "filtered_df = master_df[(master_df['date'] >= start_date) & (master_df['date'] <= end_date)]\n",
    "\n",
    "# Set 'date' column as the index\n",
    "filtered_df.set_index('date', inplace=True)\n",
    "\n",
    "# Display the first few rows to check the result\n",
    "print(filtered_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered DataFrame to a new CSV file if needed\n",
    "output_path = os.path.join(resources_path, \"filtered_master.csv\")\n",
    "filtered_df.to_csv(output_path, index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading df svc file\n",
    "df = pd.read_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date symbol        open        high         low       close  \\\n",
      "11237 2020-12-09     AI  100.000000  115.000000   90.029999   92.489998   \n",
      "11238 2020-12-10     AI   99.480003  131.746002   96.000000  130.000000   \n",
      "11239 2020-12-11     AI  123.820000  133.000000  116.000000  119.580002   \n",
      "11240 2020-12-14     AI  122.160004  123.830002  100.660004  102.360001   \n",
      "11241 2020-12-15     AI  104.570000  109.889999   98.099998  102.000000   \n",
      "11242 2020-12-16     AI  105.000000  116.709999  104.000000  113.690002   \n",
      "11243 2020-12-17     AI  118.440002  121.000000  115.449997  117.239998   \n",
      "11244 2020-12-18     AI  116.669998  145.000000  115.089996  137.589996   \n",
      "11245 2020-12-21     AI  142.014008  168.770004  141.000000  160.889999   \n",
      "11246 2020-12-22     AI  170.529999  179.000000  163.300003  177.470001   \n",
      "\n",
      "         volume  daily_return  \n",
      "11237  24805600           NaN  \n",
      "11238  22839500      0.405557  \n",
      "11239  11758600     -0.080154  \n",
      "11240   8197500     -0.144004  \n",
      "11241   5715300     -0.003517  \n",
      "11242   5365700      0.114608  \n",
      "11243   3414800      0.031225  \n",
      "11244   8486400      0.173576  \n",
      "11245  11570200      0.169344  \n",
      "11246   8283300      0.103052  \n"
     ]
    }
   ],
   "source": [
    "# THIS CODE COUNTS DAILY RETURNS FOR EACH DAY FOR EACH SYMBOL (STOCK)\n",
    "\n",
    "# Convert 'date' column to datetime type to be on the safe side as we merge several data sets\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Sort DataFrame by 'symbol' and 'date' to ensure our merged (updated) data is sorted.\n",
    "df = df.sort_values(by=['symbol', 'date'], ascending=[True, True])\n",
    "\n",
    "# Calculate the daily return for each symbol\n",
    "# It is calculated as: (current day's close - previous day's close) / previous day's close\n",
    "df['daily_return'] = df.groupby('symbol')['close'].pct_change()\n",
    "\n",
    "# Display the first few rows to check the result\n",
    "print(df.head(10))\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "df.to_csv('Resources/daily_returns_master.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   symbol  year  average_daily_return  average_closing_price  volatility\n",
      "5     AMD  2019              0.003357              31.996985    0.029594\n",
      "69   TSLA  2019              0.002608              17.666714    0.030528\n",
      "47   NVDA  2019              0.001772              45.159284    0.022850\n",
      "35   META  2019              0.001214             187.937738    0.015747\n",
      "41    NOW  2019              0.000953             265.171809    0.021432\n",
      "..    ...   ...                   ...                    ...         ...\n",
      "46    NOW  2024              0.000474             751.299313    0.018441\n",
      "4      AI  2024             -0.000895              26.397647    0.041751\n",
      "34   INDU  2024             -0.001066               7.576863    0.018357\n",
      "62   PATH  2024             -0.002413              22.040882    0.026201\n",
      "74   TSLA  2024             -0.002730             185.618530    0.035188\n",
      "\n",
      "[75 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# THIS CODE COUNTS AVERAGE DAILY RETURNS AND CLOSING PRICES PER EACH YEAR FOR EACH STOCK TO TRACK PERFORMANCE CHANGES OVER THE PERIOD\n",
    "# THIS CODE ALSO CALCULATES VOLATILITY (the standard deviation of daily returns for each symbol and year)\n",
    "\n",
    "# Convert 'date' column to datetime type to be on the safe side as we merge several data sets\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Extract the year from the date\n",
    "df['year'] = df['date'].dt.year\n",
    "\n",
    "# Calculate the daily return for each symbol\n",
    "# The daily return is calculated as: (current day's close - previous day's close) / previous day's close\n",
    "df['daily_return'] = df.groupby('symbol')['close'].pct_change()\n",
    "\n",
    "# Calculate the average daily return and average closing price for each symbol and year\n",
    "average_daily_return = df.groupby(['symbol', 'year'])['daily_return'].mean().reset_index()\n",
    "average_closing_price = df.groupby(['symbol', 'year'])['close'].mean().reset_index()\n",
    "\n",
    "# Calculate volatility (standard deviation of daily returns) for each symbol and year\n",
    "volatility = df.groupby(['symbol', 'year'])['daily_return'].std().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "average_daily_return.rename(columns={'daily_return': 'average_daily_return'}, inplace=True)\n",
    "average_closing_price.rename(columns={'close': 'average_closing_price'}, inplace=True)\n",
    "volatility.rename(columns={'daily_return': 'volatility'}, inplace=True)\n",
    "\n",
    "# Merge the DataFrames on 'symbol' and 'year'\n",
    "average_daily_statistics = pd.merge(average_daily_return, average_closing_price, on=['symbol', 'year'])\n",
    "average_daily_statistics = pd.merge(average_daily_statistics, volatility, on=['symbol', 'year'])\n",
    "\n",
    "# Sort the resulting DataFrame by 'year' and then by 'average_daily_return' in descending order\n",
    "average_daily_statistics = average_daily_statistics.sort_values(by=['year', 'average_daily_return'], ascending=[True, False])\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "average_daily_statistics.to_csv('Resources/average_daily_statistics.csv', index=False)\n",
    "\n",
    "# Display the average daily statistics\n",
    "print(average_daily_statistics)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   symbol  year  average_daily_return_per_year  average_closing_price_per_year\n",
      "46    NOW  2024                       0.000474                      751.299313\n",
      "4      AI  2024                      -0.000895                       26.397647\n",
      "34   INDU  2024                      -0.001066                        7.576863\n",
      "62   PATH  2024                      -0.002413                       22.040882\n",
      "74   TSLA  2024                      -0.002730                      185.618530\n"
     ]
    }
   ],
   "source": [
    "print(average_daily_statistics.tail(5))\n",
    "\n",
    "# this shows (please see above) that AMD, Tesla, and NVIDIA whad the best average daily returns in 2019.\n",
    "# in 2019 INDU, PATH, TSLA had the lowest avarage daily returns (please see 5 rows below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date symbol        open        high         low       close  \\\n",
      "0      2020-12-09     AI  100.000000  115.000000   90.029999   92.489998   \n",
      "240    2021-01-04     AI  131.139999  131.205002  119.059998  120.010002   \n",
      "63744  2022-01-03     AI   31.490000   32.360001   30.430000   32.299999   \n",
      "126745 2023-01-03     AI   11.430000   11.540000   10.812000   11.070000   \n",
      "189245 2024-01-02     AI   28.559999   29.730000   28.150000   28.740000   \n",
      "199649 2019-03-20    AMD   26.490000   26.879999   25.309999   25.700001   \n",
      "239051 2020-01-02    AMD   46.860001   49.250000   46.630001   49.099998   \n",
      "303060 2021-01-04    AMD   92.110001   96.059998   90.919998   92.300003   \n",
      "366564 2022-01-03    AMD  145.139999  151.649994  145.020004  150.240005   \n",
      "429565 2023-01-03    AMD   66.000000   66.879997   63.590000   64.019997   \n",
      "\n",
      "           volume  daily_return  year  cumulative_return  \n",
      "0        24805600           NaN  2020           0.405557  \n",
      "240       5123800     -0.135063  2021          -0.135063  \n",
      "63744     2767100      0.033600  2022           0.033600  \n",
      "126745    1491700     -0.010724  2023          -0.010724  \n",
      "189245    9224000      0.001045  2024           0.001045  \n",
      "199649  151292100           NaN  2019           0.085214  \n",
      "239051   80331100      0.070650  2020           0.070650  \n",
      "303060   51802600      0.006433  2021           0.006433  \n",
      "366564   59396600      0.044058  2022           0.044058  \n",
      "429565   46851800     -0.011579  2023          -0.011579  \n"
     ]
    }
   ],
   "source": [
    "# THIS CODE COUNTS CUMULATIVE RETURNS OF EACH YEAR FOR EACH SYMBOL (STOCK)\n",
    "\n",
    "# Load the new CSV file\n",
    "data_path = 'Resources/daily_returns_master.csv'\n",
    "yearly_df = pd.read_csv(data_path)\n",
    "\n",
    "# Convert 'date' column to datetime type to be on the safe side as we merge several data sets\n",
    "yearly_df['date'] = pd.to_datetime(yearly_df['date'])\n",
    "\n",
    "# Extract the year from the date\n",
    "yearly_df['year'] = yearly_df['date'].dt.year\n",
    "\n",
    "# Ensure daily returns are numerical\n",
    "if yearly_df['daily_return'].dtype == 'object':\n",
    "    yearly_df['daily_return'] = yearly_df['daily_return'].str.rstrip('%').astype('float') / 100.0\n",
    "else:\n",
    "    yearly_df['daily_return'] = yearly_df['daily_return'].astype('float')\n",
    "\n",
    "# Define a function to calculate cumulative returns\n",
    "def cumulative_return(x):\n",
    "    return (1 + x.dropna()).cumprod() - 1\n",
    "\n",
    "# Apply cumulative return calculation to each group and get the last value of each year\n",
    "cumulative_returns = yearly_df.groupby(['symbol', 'year'])['daily_return'].apply(cumulative_return).reset_index()\n",
    "\n",
    "# Merge the cumulative returns back to the original DataFrame\n",
    "yearly_df = yearly_df.merge(cumulative_returns[['symbol', 'year', 'daily_return']], on=['symbol', 'year'], how='left', suffixes=('', '_cumulative'))\n",
    "\n",
    "# Rename the merged column to 'cumulative_return'\n",
    "yearly_df.rename(columns={'daily_return_cumulative': 'cumulative_return'}, inplace=True)\n",
    "\n",
    "# Drop duplicates and NaN values\n",
    "yearly_df.drop_duplicates(subset=['symbol', 'year'], inplace=True)\n",
    "yearly_df.dropna(subset=['cumulative_return'], inplace=True)\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "output_path = 'Resources/yearly_returns_master.csv'\n",
    "yearly_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Display the first few rows to check the result\n",
    "print(yearly_df.head(10))\n",
    "\n",
    "## IMPORTANT: this code shows the value of cumulative return on the row with the first date of the corresponding year.\n",
    "## this way we can track stocks that appeared on the stock market later or to highlight the data limitation of the free data we exported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   symbol  average_yearly_return  average_yearly_closing_price\n",
      "5    INDU               0.015390                      7.225000\n",
      "12   TSLA               0.015065                    174.437888\n",
      "1     AMD               0.009932                     86.656668\n",
      "2    AMZN               0.007224                    125.041664\n",
      "6    META               0.005605                    242.288336\n",
      "8    NVDA               0.000082                    193.458745\n",
      "11    SPY              -0.001656                    384.398333\n",
      "4     DOW              -0.003947                     53.471667\n",
      "9    PANW              -0.008614                    147.733892\n",
      "3    ANET              -0.009983                    115.215418\n",
      "7     NOW              -0.014898                    460.970006\n",
      "10   PATH              -0.019252                     37.240000\n",
      "0      AI              -0.027785                     56.922000\n"
     ]
    }
   ],
   "source": [
    "# THIS CODE COUNTS AVERAGE CUMULATIVE RETURNS AND AV.CLOSING PRICES FOR THE LAST 5 YEARS FOR EACH STOCK TO DISPLAY OVERALL COMPANY STANDING IN THE ANALYZED PERIOD\n",
    "\n",
    "# Calculate the average yearly returns and average yearly closing prices for each symbol\n",
    "average_yearly_return = yearly_df.groupby(['symbol', 'year'])['daily_return'].mean().reset_index()\n",
    "average_yearly_closing_price = yearly_df.groupby(['symbol', 'year'])['close'].mean().reset_index()\n",
    "\n",
    "# Calculate the average return and average closing price across all years for each symbol\n",
    "average_yearly_return = average_yearly_return.groupby('symbol')['daily_return'].mean().reset_index()\n",
    "average_yearly_closing_price = average_yearly_closing_price.groupby('symbol')['close'].mean().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "average_yearly_return.rename(columns={'daily_return': 'average_yearly_return'}, inplace=True)\n",
    "average_yearly_closing_price.rename(columns={'close': 'average_yearly_closing_price'}, inplace=True)\n",
    "\n",
    "# Merge the two DataFrames on 'symbol'\n",
    "average_yearly_statistics = pd.merge(average_yearly_return, average_yearly_closing_price, on='symbol')\n",
    "\n",
    "# Sort the resulting DataFrame by 'average_yearly_return' in descending order\n",
    "average_yearly_statistics = average_yearly_statistics.sort_values(by='average_yearly_return', ascending=False)\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "average_yearly_statistics.to_csv('Resources/average_yearly_statistics.csv', index=False)\n",
    "\n",
    "# Display the average yearly statistics\n",
    "print(average_yearly_statistics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
