{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "import pingouin as pg # for post-host pairwise test\n",
    "from statsmodels.stats.anova import AnovaRM # for anova test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3921, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cg/fw0l8qy135x2sls4z7q4jwh00000gn/T/ipykernel_45299/2820423153.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stock_data.dropna(inplace= True)\n",
      "/var/folders/cg/fw0l8qy135x2sls4z7q4jwh00000gn/T/ipykernel_45299/2820423153.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ai_daily['date'] = pd.to_datetime(ai_daily['date'])\n",
      "/var/folders/cg/fw0l8qy135x2sls4z7q4jwh00000gn/T/ipykernel_45299/2820423153.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ai_daily['year'] = ai_daily['date'].dt.year\n",
      "/var/folders/cg/fw0l8qy135x2sls4z7q4jwh00000gn/T/ipykernel_45299/2820423153.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df.dropna(inplace= True)\n",
      "/var/folders/cg/fw0l8qy135x2sls4z7q4jwh00000gn/T/ipykernel_45299/2820423153.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  index_daily['date'] = pd.to_datetime(index_daily['date'])\n",
      "/var/folders/cg/fw0l8qy135x2sls4z7q4jwh00000gn/T/ipykernel_45299/2820423153.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  index_daily['year'] = index_daily['date'].dt.year\n",
      "/var/folders/cg/fw0l8qy135x2sls4z7q4jwh00000gn/T/ipykernel_45299/2820423153.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#>>> Loading data from Nate's boxplot & anova code\n",
    "\n",
    "#path for data\n",
    "daily_master_path = 'Resources/daily_returns_master.csv'\n",
    "daily_stats_path = 'Resources/average_daily_statistics.csv'\n",
    "yearly_master_path = 'Resources/yearly_returns_master.csv'\n",
    "yearly_stats_path = 'Resources/average_yearly_statistics.csv'\n",
    "kaggle_clean_path = 'Resources/kaggle_clean.csv'\n",
    "\n",
    "#load data into pandas\n",
    "daily_master_df = pd.read_csv(daily_master_path)\n",
    "daily_stats_df = pd.read_csv(daily_stats_path)\n",
    "yearly_stats_df = pd.read_csv(yearly_stats_path)\n",
    "yearly_master_df = pd.read_csv(yearly_master_path)\n",
    "kaggle_clean_df = pd.read_csv(kaggle_clean_path)\n",
    "\n",
    "#Generate symbol list for each classification\n",
    "symbols = daily_master_df['symbol'].unique()\n",
    "ai_symbols = kaggle_clean_df['symbol'].unique()\n",
    "index_symbols = np.array([sym for sym in symbols if sym not in ai_symbols])\n",
    "\n",
    "#segment dataframes for each box plot\n",
    "# daily_master_df has all\n",
    "ai_daily = daily_master_df[daily_master_df['symbol'].isin(ai_symbols)]\n",
    "index_daily = daily_master_df[daily_master_df['symbol'].isin(index_symbols)]\n",
    "\n",
    "ai_only_all_years = [daily_master_df[daily_master_df['symbol'].eq(sym)]['daily_return'] for sym in ai_symbols]\n",
    "for stock_data in ai_only_all_years:\n",
    "    stock_data.dropna(inplace= True)\n",
    "\n",
    "   #Generate a yea column to group by\n",
    "ai_daily['date'] = pd.to_datetime(ai_daily['date'])\n",
    "ai_daily['year'] = ai_daily['date'].dt.year\n",
    "\n",
    "#process the ai data by year to generate a list of daily returns for each year.\n",
    "ai_comps_dr_grouped_year = ai_daily.groupby('year')\n",
    "grp_name_yrs = ai_comps_dr_grouped_year.groups.keys()\n",
    "years_titles = list(grp_name_yrs)\n",
    "\n",
    "years_data_ai = []\n",
    "for year in grp_name_yrs:\n",
    "    temp_df = ai_comps_dr_grouped_year.get_group(year)\n",
    "    temp_df.dropna(inplace= True)\n",
    "    years_data_ai.append(temp_df)\n",
    "    #Generate a yea column to group by\n",
    "index_daily['date'] = pd.to_datetime(index_daily['date'])\n",
    "index_daily['year'] = index_daily['date'].dt.year\n",
    "print(index_daily.shape)\n",
    "\n",
    "#process the ai data by year to generate a list of daily returns for each year.\n",
    "index_dr_grouped_year_sym = index_daily.groupby(['year', 'symbol'])\n",
    "idx_grp_names = index_dr_grouped_year_sym.groups.keys()\n",
    "year_sym_titles = list(idx_grp_names)\n",
    "year_sym_titles\n",
    "\n",
    "#collect each index ETF data grouped by years into seperate lists\n",
    "years_data_SPY = []\n",
    "years_data_DOW = []\n",
    "years_data_INDU = []\n",
    "\n",
    "for label in year_sym_titles:\n",
    "    # temp_df = ai_comps_dr_grouped_year.get_group(year)\n",
    "    # years_data_ai.append(temp_df)\n",
    "    temp_df = index_dr_grouped_year_sym.get_group(label)\n",
    "    temp_df.dropna(inplace=True)\n",
    "    if 'SPY' in label:\n",
    "        years_data_SPY.append(temp_df)\n",
    "    elif 'DOW' in label:\n",
    "        years_data_DOW.append(temp_df)\n",
    "    elif 'INDU' in label:\n",
    "        years_data_INDU.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock</th>\n",
       "      <th>Year</th>\n",
       "      <th>Avg_daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPY</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.000706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOW</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.000695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDU</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>-0.002639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AI_avg</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.001057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPY</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>0.000816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOW</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>0.000835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDU</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>0.001153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AI_avg</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>0.003802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPY</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>0.000984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOW</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDU</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>0.003305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AI_avg</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>0.000911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPY</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>-0.000746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOW</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>-0.000292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDU</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>-0.001086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AI_avg</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>-0.002200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPY</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>0.000904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOW</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>0.000436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDU</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>0.001621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AI_avg</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>0.003803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPY</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>0.001090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOW</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>0.000619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDU</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>-0.001066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AI_avg</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>0.001455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Stock    Year  Avg_daily_return\n",
       "0     SPY  2019.0          0.000706\n",
       "1     DOW  2019.0          0.000695\n",
       "2    INDU  2019.0         -0.002639\n",
       "3  AI_avg  2019.0          0.001057\n",
       "0     SPY  2020.0          0.000816\n",
       "1     DOW  2020.0          0.000835\n",
       "2    INDU  2020.0          0.001153\n",
       "3  AI_avg  2020.0          0.003802\n",
       "0     SPY  2021.0          0.000984\n",
       "1     DOW  2021.0          0.000254\n",
       "2    INDU  2021.0          0.003305\n",
       "3  AI_avg  2021.0          0.000911\n",
       "0     SPY  2022.0         -0.000746\n",
       "1     DOW  2022.0         -0.000292\n",
       "2    INDU  2022.0         -0.001086\n",
       "3  AI_avg  2022.0         -0.002200\n",
       "0     SPY  2023.0          0.000904\n",
       "1     DOW  2023.0          0.000436\n",
       "2    INDU  2023.0          0.001621\n",
       "3  AI_avg  2023.0          0.003803\n",
       "0     SPY  2024.0          0.001090\n",
       "1     DOW  2024.0          0.000619\n",
       "2    INDU  2024.0         -0.001066\n",
       "3  AI_avg  2024.0          0.001455"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Merging data for ANOVA analysis. Nate's code: \n",
    "#declare the data structure of the dataframe\n",
    "data_dict = {\n",
    "        'Stock' : [],\n",
    "        'Year' : [],\n",
    "        'Avg_daily_return' : []\n",
    "        }\n",
    "# declare the dataframe to be added to with correct column names\n",
    "combined_df = pd.DataFrame(data_dict)\n",
    "\n",
    "for year_index in [0, 1 , 2, 3, 4, 5]:\n",
    "    # make the means\n",
    "    this_year_spy_mean = years_data_SPY[year_index]['daily_return'].mean()\n",
    "    this_year_dow_mean = years_data_DOW[year_index]['daily_return'].mean()\n",
    "    this_year_indu_mean = years_data_INDU[year_index]['daily_return'].mean()\n",
    "    this_year_ai_mean = years_data_ai[year_index]['daily_return'].mean()\n",
    "    #pick the year\n",
    "    this_year = years_titles[year_index]\n",
    "    #make the columns of data\n",
    "    data_dict['Stock'] = ['SPY', 'DOW', 'INDU', 'AI_avg']\n",
    "    data_dict['Year'] = [this_year] * 4\n",
    "    data_dict['Avg_daily_return'] = [this_year_spy_mean, this_year_dow_mean, this_year_indu_mean, this_year_ai_mean]\n",
    "    #generate the dataframe for this year\n",
    "    partial_df = pd.DataFrame(data_dict)\n",
    "    #concat this year with all prev years\n",
    "    combined_df = pd.concat([combined_df, partial_df])\n",
    "# display    \n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "##--- Stat Analysis #1: Repeated Measures ANOVA---##\n",
    "# Null (H0): mu_AI_avg = mu_spy = mu_dow = mu_indu\n",
    "# Alternatie (Ha): at least one mu_i is different\n",
    "####################################################\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
